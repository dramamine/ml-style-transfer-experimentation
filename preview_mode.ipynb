{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preview_mode.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dramamine/ml-style-transfer-experimentation/blob/multi-preview/preview_mode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpWwQOT8rzG"
      },
      "source": [
        "## Preview Image Styles\n",
        "\n",
        "Here's what we're going for:\n",
        "\n",
        "![](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/table.png)\n",
        "\n",
        "TODO:  Link to inspiration demos and credit sources\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r5c0g7PKlbF"
      },
      "source": [
        "# Here's the rough plan:\n",
        "\n",
        "# V0 - take two images, run them at 1x1 ‚úÖ\n",
        "# V1 - take two directories of 2 images, run them at 1x1, display in a grid with originals\n",
        "\n",
        "# Stretch goals\n",
        "# - add \"random sample\" mode for pulling handful of imgs from dir\n",
        "# - directory chooser / file browser\n",
        "# - add \"pick your images\" mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbnKDG4jgJf4",
        "cellView": "form"
      },
      "source": [
        "# Here's how to import from our github for these files!\n",
        "branch_name = 'main' #@param\n",
        "\n",
        "# Start from /content/ dir, clone git repo\n",
        "%cd /content\n",
        "%rm -rf ml-style-transfer-experimentation\n",
        "!git clone https://github.com/dramamine/ml-style-transfer-experimentation\n",
        "\n",
        "# cd into git repo, change branch\n",
        "%cd ml-style-transfer-experimentation\n",
        "!git checkout $branch_name\n",
        "\n",
        "# import python files\n",
        "from lib.utils import test_a_python_import_from_github\n",
        "from lib.utils import StepTimer\n",
        "test_a_python_import_from_github()\n",
        "\n",
        "# back to base directory\n",
        "%cd /content\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciYyUYVZT4IA",
        "cellView": "form"
      },
      "source": [
        "#@title 0. Install Dependencies üß∞\n",
        "#@markdown Install dependencies. ***Probably don't modify this?*** The setup should not take more than two minutes. \n",
        "print(\"Installing tf-nightly...\")\n",
        "!pip uninstall -q -y tensorflow \n",
        "!pip install -q tf-nightly\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        " \n",
        "clear_output()\n",
        "\n",
        "print(\"tf-nightly installed.\")\n",
        "\n",
        "# Download the style bottleneck and transfer networks\n",
        "print('Downloading the model files...')\n",
        "\n",
        "style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/int8/predict/1?lite-format=tflite')\n",
        "style_transform_path = style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/int8/transfer/1?lite-format=tflite')\n",
        "\n",
        "print('Model files downloaded...')\n",
        "\n",
        "# other deps\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "\n",
        "print('You are all set!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVyDbPBUxhwm"
      },
      "source": [
        "#\n",
        "# Import Style Transfer Utils\n",
        "#\n",
        "%cd ml-style-transfer-experimentation\n",
        "import lib.style_transfer_utils as sxu\n",
        "print('')\n",
        "print('üëç imported style transfer utils üëç') if sxu else print('üíÄ ERROR üíÄ')\n",
        "print('')\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeQnyEePZgo6",
        "cellView": "form"
      },
      "source": [
        "#@title OLD - Load Library Code - now sourced from GH\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "from types import SimpleNamespace\n",
        "\n",
        "style_predict_path = tf.keras.utils.get_file(\n",
        "    'style_predict.tflite', 'https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/int8/predict/1?lite-format=tflite')\n",
        "style_transform_path = style_transform_path = tf.keras.utils.get_file(\n",
        "    'style_transform.tflite', 'https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/int8/transfer/1?lite-format=tflite')\n",
        "\n",
        "STYLE_SIZE = 256\n",
        "CONTENT_SIZE = 384\n",
        "\n",
        "def imshow(image, title=None):\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "\n",
        "def get_array_of_pieces(img, cfg):\n",
        "  cols = cfg.cols\n",
        "  rows = cfg.rows\n",
        "  edge_size = cfg.edge_size\n",
        "\n",
        "  pieces = []\n",
        "  #print(title, \"image size:\", img.size)\n",
        "  w = math.floor(img.size[0]/cols)\n",
        "  h = math.floor(img.size[1]/rows)\n",
        "  #print(\"using cell size:\", w, \"x\", h)\n",
        "\n",
        "  if (w < STYLE_SIZE or h < STYLE_SIZE):\n",
        "    print(\"WARNING: That size seems a bit small and will probably result in stretching.\")\n",
        "\n",
        "  # scale edge_size\n",
        "  we = w*edge_size/CONTENT_SIZE\n",
        "  he = h*edge_size/CONTENT_SIZE\n",
        "\n",
        "  for r in range(0, rows):\n",
        "    for c in range(0, cols):\n",
        "      el = 0 if c == 0 else we\n",
        "      er = 0 if c == cols-1 else we\n",
        "      eu = 0 if r == 0 else he\n",
        "      ed = 0 if r == rows-1 else he\n",
        "\n",
        "      region = img.crop((c*w-el, r*h-eu, (c+1)*w+er, (r+1)*h+ed))\n",
        "      pieces.append(region)\n",
        "  return pieces\n",
        "\n",
        "def get_intermediate_tiles(img, cfg):\n",
        "  cols = cfg.cols\n",
        "  rows = cfg.rows\n",
        "  edge_size = cfg.edge_size\n",
        "\n",
        "  row_pieces = []\n",
        "  column_pieces = []\n",
        "  # print(title,\"image size:\", img.size)\n",
        "  w = math.floor(img.size[0]/cols)\n",
        "  h = math.floor(img.size[1]/rows)\n",
        "\n",
        "  # scale edge_size\n",
        "  we = w*edge_size/STYLE_SIZE\n",
        "  he = h*edge_size/STYLE_SIZE\n",
        "\n",
        "  for r in range(0, rows):\n",
        "    for c in range(0, cols-1):\n",
        "      el = 0 if c == 0 else we\n",
        "      er = 0 if c == cols-1 else we\n",
        "      eu = 0 if r == 0 else he\n",
        "      ed = 0 if r == rows-1 else he\n",
        "\n",
        "      region = img.crop(((c+0.5)*w-el, r*h-eu, (c+1.5)*w+er, (r+1)*h+ed))\n",
        "      row_pieces.append(region)\n",
        "\n",
        "  for r in range(0, rows-1):\n",
        "    for c in range(0, cols):\n",
        "      el = 0 if c == 0 else we\n",
        "      er = 0 if c == cols-1 else we\n",
        "      eu = 0 if r == 0 else he\n",
        "      ed = 0 if r == rows-1 else he\n",
        "\n",
        "      region = img.crop(((c)*w-el, (r+0.5)*h-eu, (c+1)*w+er, (r+1.5)*h+ed))\n",
        "      column_pieces.append(region)\n",
        "\n",
        "  return [row_pieces, column_pieces]\n",
        "\n",
        "\n",
        "def load_img(path_to_img):\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "\n",
        "\n",
        "\n",
        "# Function to load an image from a file, and add a batch dimension.\n",
        "def load_content_img(image_pixels):\n",
        "    if image_pixels.shape[-1] == 4:\n",
        "        image_pixels = Image.fromarray(image_pixels)\n",
        "        img = image_pixels.convert('RGB')\n",
        "        img = np.array(img)\n",
        "        img = tf.convert_to_tensor(img)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "        img = img[tf.newaxis, :]\n",
        "        return img\n",
        "    elif image_pixels.shape[-1] == 3:\n",
        "        img = tf.convert_to_tensor(image_pixels)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "        img = img[tf.newaxis, :]\n",
        "        return img\n",
        "    elif image_pixels.shape[-1] == 1:\n",
        "        raise Error(\n",
        "            'Grayscale images not supported! Please try with RGB or RGBA images.')\n",
        "    print('Exception not thrown')\n",
        "\n",
        "\n",
        "\n",
        "# Function to pre-process by resizing an central cropping it.\n",
        "def preprocess_image(image, target_dim):\n",
        "  # Resize the image so that the shorter dimension becomes 256px.\n",
        "  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)\n",
        "  short_dim = min(shape)\n",
        "  scale = target_dim / short_dim\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  image = tf.image.resize(image, new_shape)\n",
        "\n",
        "  # Central crop the image.\n",
        "  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)\n",
        "\n",
        "  return image\n",
        "\n",
        "# Function to run style prediction on preprocessed style image.\n",
        "\n",
        "def run_style_predict(preprocessed_style_image):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_predict_path)\n",
        "\n",
        "  # Set model input.\n",
        "  interpreter.allocate_tensors()\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_style_image)\n",
        "\n",
        "  # Calculate style bottleneck.\n",
        "  interpreter.invoke()\n",
        "  style_bottleneck = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "  )()\n",
        "  # print('Style Bottleneck Shape:', style_bottleneck.shape)\n",
        "  return style_bottleneck\n",
        "\n",
        "def preprocessor(img, res):\n",
        "  img = load_content_img(np.array(img))\n",
        "  return preprocess_image(img, res)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_style_transform(style_bottleneck, preprocessed_content_image):\n",
        "  # Load the model.\n",
        "  interpreter = tf.lite.Interpreter(model_path=style_transform_path)\n",
        "\n",
        "  # Set model input.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  # Set model inputs.\n",
        "  for index in range(len(input_details)):\n",
        "    if input_details[index][\"name\"] == 'Conv/BiasAdd':\n",
        "      interpreter.set_tensor(input_details[index][\"index\"], style_bottleneck)\n",
        "    elif input_details[index][\"name\"] == 'content_image':\n",
        "      interpreter.set_tensor(\n",
        "          input_details[index][\"index\"], preprocessed_content_image)\n",
        "  interpreter.invoke()\n",
        "\n",
        "  # Transform content image.\n",
        "  stylized_image = interpreter.tensor(\n",
        "      interpreter.get_output_details()[0][\"index\"]\n",
        "  )()\n",
        "\n",
        "  return stylized_image\n",
        "\n",
        "\n",
        "def stylize(preprocessed_content_image, style_bottleneck, style_bottleneck_content, content_blending_ratio):\n",
        "  # Blend the style bottleneck of style image and content image\n",
        "  style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \\\n",
        "      + (1 - content_blending_ratio) * style_bottleneck\n",
        "\n",
        "  # Stylize the content image using the style bottleneck.\n",
        "  stylized_image = run_style_transform(\n",
        "      style_bottleneck_blended, preprocessed_content_image)\n",
        "\n",
        "  print('üêå', end=\"\")\n",
        "  return stylized_image\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  y = np.zeros(len(x))\n",
        "  for i in range(len(x)):\n",
        "    y[i] = 255 / (1 + math.exp(-x[i]))\n",
        "  return y\n",
        "\n",
        "# generate sigmoid.\n",
        "# size: the width and height in pixels\n",
        "# magnitude: the strength of the sigmoid - higher values = sharper transition.\n",
        "#            must be >0, increases above 100 don't make much difference\n",
        "# flip: if true, values change across the y-axis\n",
        "\n",
        "\n",
        "def generate_sigmoid(size, magnitude=6, flip=False):\n",
        "  m = magnitude/10\n",
        "  sigmoid_ = sigmoid(np.concatenate((np.arange(-m, m, 4*m/size),\n",
        "                                     np.arange(m, -m, -4*m/size))))\n",
        "  alpha = np.repeat(sigmoid_.reshape((len(sigmoid_), 1)), repeats=size, axis=1)\n",
        "  if flip:\n",
        "    alpha = np.swapaxes(alpha, 0, 1)\n",
        "  res = Image.fromarray(np.uint8(alpha), 'L')\n",
        "  return res\n",
        "\n",
        "\n",
        "def sew(stylized_pieces, cfg):\n",
        "  cols = cfg.cols\n",
        "  rows = cfg.rows\n",
        "  edge_size = cfg.edge_size\n",
        "  wh = cfg.content_size\n",
        "\n",
        "  im = Image.new('RGB', (\n",
        "      cols*wh-2*edge_size*(cols-1),\n",
        "      rows*wh-2*edge_size*(rows-1)\n",
        "  ))\n",
        "\n",
        "  for r in range(0, rows):\n",
        "    for c in range(0, cols):\n",
        "      squeezed = tf.squeeze(stylized_pieces[c+r*cols])\n",
        "      imaged = tf.keras.preprocessing.image.array_to_img(squeezed)\n",
        "\n",
        "      el = 0 if c == 0 else edge_size\n",
        "      er = 0 if c == cols-1 else edge_size\n",
        "      eu = 0 if r == 0 else edge_size\n",
        "      ed = 0 if r == rows-1 else edge_size\n",
        "\n",
        "      print(\"imaged size:\")\n",
        "      print(imaged.size)\n",
        "      cropped = imaged.crop((el, eu, wh-er, wh-ed))\n",
        "      print(\"cropped size:\")\n",
        "      print(cropped.size)\n",
        "\n",
        "      im.paste(cropped, (\n",
        "          c*wh - max(0, (2*c-1)*el),  # left\n",
        "          r*wh - max(0, (2*r-1)*eu)  # up\n",
        "      ))\n",
        "  return im\n",
        "\n",
        "def apply_row_joints(orig, joints, cfg):\n",
        "  cols = cfg.cols\n",
        "  rows = cfg.rows\n",
        "  edge_size = cfg.edge_size\n",
        "  wh = cfg.content_size\n",
        "  magnitude = cfg.magnitude\n",
        "\n",
        "  updated_image = orig.copy()\n",
        "  mask = generate_sigmoid(384, magnitude, True)\n",
        "  assert(rows*(cols-1) == len(joints))\n",
        "\n",
        "  for r in range(0, rows):\n",
        "    for c in range(0, cols-1):\n",
        "      squeezed = tf.squeeze(joints[c+r*(cols-1)])\n",
        "      imaged = tf.keras.preprocessing.image.array_to_img(squeezed)\n",
        "\n",
        "      el = 0 if c == 0 else edge_size\n",
        "      er = 0 if c == cols-1 else edge_size\n",
        "      eu = 0 if r == 0 else edge_size\n",
        "      ed = 0 if r == rows-1 else edge_size\n",
        "\n",
        "      cropped = imaged.crop((el, eu, wh-er, wh-ed))\n",
        "\n",
        "      # blackbox = Image.new('RGB', cropped.size, 0)\n",
        "      updated_image.paste(cropped, (\n",
        "          int((0.5+c)*wh - (0.5*edge_size + 1.5*edge_size*c)),  # left\n",
        "          r*wh - max(0, (2*r-1)*eu)  # up\n",
        "      ), mask.resize(cropped.size))\n",
        "  return updated_image\n",
        "\n",
        "\n",
        "def apply_column_joints(orig, joints, cfg):\n",
        "  cols = cfg.cols\n",
        "  rows = cfg.rows\n",
        "  edge_size = cfg.edge_size\n",
        "  wh = cfg.content_size\n",
        "  magnitude = cfg.magnitude\n",
        "\n",
        "  updated_image = orig.copy()\n",
        "  mask = generate_sigmoid(384, magnitude, False)\n",
        "  assert(((rows-1)*cols) == len(joints))\n",
        "\n",
        "  for r in range(0, rows-1):\n",
        "    for c in range(0, cols):\n",
        "      squeezed = tf.squeeze(joints[c+r*cols])\n",
        "      imaged = tf.keras.preprocessing.image.array_to_img(squeezed)\n",
        "\n",
        "      el = 0 if c == 0 else edge_size\n",
        "      er = 0 if c == cols-1 else edge_size\n",
        "      eu = 0 if r == 0 else edge_size\n",
        "      ed = 0 if r == rows-1 else edge_size\n",
        "\n",
        "      cropped = imaged.crop((el, eu, wh-er, wh-ed))\n",
        "\n",
        "      # blackbox = Image.new('RGB', cropped.size, 0)\n",
        "      updated_image.paste(cropped, (\n",
        "          c*wh - max(0, (2*c-1)*el),  # left\n",
        "          int((0.5+r)*wh - (0.5*edge_size + 1.5*edge_size*r))  # up\n",
        "      ), mask.resize(cropped.size))\n",
        "  return updated_image\n",
        "\n",
        "def get_nice_name(path):\n",
        "  # @TODO Windows split on backslash\n",
        "  filename = path.split('/')[-1]\n",
        "  return filename.split('.')[0]\n",
        "\n",
        "def get_output_filename(content_image_path, style_image_path, \n",
        "                        content_blending_ratio, edge_size, \n",
        "                        use_tiled_style_image, use_fluid_blend, magnitude,\n",
        "                        extra_id=\"\", **kwargs):\n",
        "  content_blending_ratio = float(content_blending_ratio)\n",
        "  output = \"{0}-{1}-hd-fusion-blend{2}-edge{3}{4}{5}{6}.jpg\".format(\n",
        "      get_nice_name(content_image_path),\n",
        "      get_nice_name(style_image_path),\n",
        "      int(10*content_blending_ratio),\n",
        "      edge_size,\n",
        "      \"-tiled\" if use_tiled_style_image else \"\",\n",
        "      \"-fluid{0}\".format(magnitude) if use_fluid_blend else \"\",\n",
        "      extra_id\n",
        "  )\n",
        "  return output\n",
        "\n",
        "def render(\n",
        "    drive_base,\n",
        "    content_image_path,\n",
        "    style_image_path,\n",
        "    cols=4,\n",
        "    rows=3,\n",
        "    use_tiled_style_image=False,\n",
        "    use_fluid_blend=True,\n",
        "    edge_size=4,\n",
        "    magnitude=6,\n",
        "    content_blending_ratio=0.5\n",
        "):\n",
        "  # time.sleep(1)\n",
        "  print(\"starting render\")\n",
        "  config = dict(cols=cols, rows=rows, edge_size=edge_size, magnitude=magnitude, content_size=CONTENT_SIZE, style_size=STYLE_SIZE)\n",
        "  config = SimpleNamespace(**config)\n",
        "\n",
        "  content_image = Image.open(drive_base+content_image_path)\n",
        "  style_image = Image.open(drive_base+style_image_path)\n",
        "  \n",
        "  content_pieces = get_array_of_pieces(content_image, config)\n",
        "  if use_tiled_style_image:\n",
        "    style_pieces = get_array_of_pieces(style_image, config)\n",
        "  else:\n",
        "    style_pieces = list([style_image])\n",
        "\n",
        "  if use_fluid_blend:\n",
        "    (row_joints, col_joints) = get_intermediate_tiles(content_image, config)\n",
        "    # print(\"Row joints:\", len(row_joints), \"Col joints:\", len(col_joints))\n",
        "    content_pieces.extend(row_joints)\n",
        "    content_pieces.extend(col_joints)\n",
        " \n",
        "  tf_content_pieces = list(map(lambda x: load_content_img(np.array(x)), content_pieces))\n",
        "  preprocessed_content_pieces = list(map(lambda x: preprocessor(x, CONTENT_SIZE), content_pieces))\n",
        "  preprocessed_style_pieces = list(map(lambda x: preprocessor(x, STYLE_SIZE), style_pieces))\n",
        "\n",
        "  style_bottlenecks = list(map(lambda x: run_style_predict(x), preprocessed_style_pieces))\n",
        "  style_bottleneck_contents = list(map(lambda x: run_style_predict(preprocess_image(x, STYLE_SIZE)), tf_content_pieces))\n",
        "\n",
        "  print(\"Processing\", len(preprocessed_content_pieces), \"cells of content...\")\n",
        "\n",
        "  if use_tiled_style_image:\n",
        "    stylized_pieces = list(map(lambda x, y, z: stylize(\n",
        "        x, y, z, content_blending_ratio), preprocessed_content_pieces, style_bottlenecks, style_bottleneck_contents))\n",
        "  else:\n",
        "    stylized_pieces = list(map(lambda x, z: stylize(\n",
        "        x, style_bottlenecks[0], z, content_blending_ratio), preprocessed_content_pieces, style_bottleneck_contents))\n",
        "\n",
        "  image = sew(stylized_pieces, config)\n",
        "\n",
        "  if use_fluid_blend:\n",
        "    row_joints = stylized_pieces[(rows*cols):(rows*cols+rows*(cols-1))]\n",
        "    column_joints = stylized_pieces[(rows*cols+rows*(cols-1)):]\n",
        "    image = apply_column_joints(\n",
        "        apply_row_joints(image, row_joints, config), column_joints, config)\n",
        "\n",
        "  output_filename = \"{0}output/{1}\".format(drive_base, get_output_filename(\n",
        "    content_image_path=content_image_path,\n",
        "    style_image_path=style_image_path,\n",
        "    content_blending_ratio=content_blending_ratio,\n",
        "    edge_size=edge_size,\n",
        "    use_tiled_style_image=use_tiled_style_image,\n",
        "    use_fluid_blend=use_fluid_blend,\n",
        "    magnitude=magnitude\n",
        "  ))\n",
        "  image.save(output_filename, \"JPEG\")\n",
        "  print(\"Saved to:\", output_filename)\n",
        "  return image\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPf_hsc9Z25y",
        "cellView": "form"
      },
      "source": [
        "#@title 2. Mount Google Drive\n",
        "\n",
        "print(\"Mounting google drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mgx257IRbYA"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "def load_or_render_preview_cell(content_image_path, style_image_path, blend_ratio, base_dir, output_dir):\n",
        "  params = dict(\n",
        "    # inputs\n",
        "    content_image_path=content_image_path,\n",
        "    style_image_path=style_image_path,\n",
        "    content_blending_ratio=blend_ratio,\n",
        "    # preview param settings\n",
        "    rows=1,\n",
        "    cols=1,\n",
        "    use_tiled_style_image=False,\n",
        "    use_fluid_blend=False,\n",
        "    edge_size=8,\n",
        "    magnitude=2,\n",
        "    # file locations\n",
        "    drive_base=base_dir,\n",
        "    output_directory=output_dir,\n",
        "  )\n",
        "\n",
        "  # Check to see if we already rendered this preview, and return it if so\n",
        "  target_filename = output_dir + sxu.get_output_filename(**params)\n",
        "  if os.path.isfile(target_filename):\n",
        "    return Image.open(target_filename)\n",
        "\n",
        "  # Render the preview and log the timing\n",
        "  with StepTimer('[[TIMING]] Render preview image'):\n",
        "    return sxu.run(**params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEfBMoZoYpLn"
      },
      "source": [
        "from PIL import Image\n",
        "# square and center the image by removing extra height or width\n",
        "def square_crop_and_center(img):\n",
        "  width, height = img.size\n",
        "  new_width = new_height = min(width, height)\n",
        "\n",
        "  left = (width - new_width)/2\n",
        "  top = (height - new_height)/2\n",
        "  right = (width + new_width)/2\n",
        "  bottom = (height + new_height)/2\n",
        "\n",
        "  return img.crop((left, top, right, bottom))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbwAyRrCaRam"
      },
      "source": [
        "#@title 3. Run It\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "#\n",
        "# Preview Grid Parameters\n",
        "#\n",
        "gdrive_basedir = '/content/drive/MyDrive/images/' #@param\n",
        "\n",
        "content_image_1 = 'dude1.jpg' #@param\n",
        "style_image_1 = 'water.jpg' #@param\n",
        "\n",
        "content_image_2 = 'backyard.jpg' #@param\n",
        "style_image_2 = 'winter.jpg' #@param\n",
        "\n",
        "content_blending_ratio = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "gdrive_outdir = '/content/drive/MyDrive/images/previews/' #@param\n",
        "\n",
        "#\n",
        "# debug input arrays\n",
        "#\n",
        "\n",
        "content_imgs = [content_image_1, content_image_2]\n",
        "style_imgs = [style_image_1, style_image_2]\n",
        "\n",
        "#\n",
        "# Render Preview Grid\n",
        "#\n",
        "\n",
        "content_len = len(content_imgs)\n",
        "style_len = len(style_imgs)\n",
        "\n",
        "# initialize preview grid\n",
        "preview_grid, subplots = plt.subplots(content_len+1, style_len+1)\n",
        "\n",
        "# remove ALL grid axes\n",
        "for ii in range(content_len+1):\n",
        "  for jj in range(style_len+1):\n",
        "    subplots[ii, jj].axis('off')\n",
        "\n",
        "# show content and style images (crop to content size)\n",
        "for ii in range(content_len):\n",
        "  for jj in range(style_len):\n",
        "    subplots[ii+1, 0].imshow(\n",
        "      square_crop_and_center(\n",
        "        Image.open(gdrive_basedir + content_imgs[ii])\n",
        "      )\n",
        "    )\n",
        "    subplots[0, jj+1].imshow(\n",
        "      square_crop_and_center(\n",
        "        Image.open(gdrive_basedir + style_imgs[jj])\n",
        "      )\n",
        "    )\n",
        "\n",
        "# render preview grid\n",
        "for ii in range(content_len):\n",
        "  for jj in range(style_len):\n",
        "    content_image_path = content_imgs[ii]\n",
        "    style_image_path = style_imgs[jj]\n",
        "\n",
        "    result_plot = subplots[ii+1, jj+1]\n",
        "    result = load_or_render_preview_cell(\n",
        "      content_image_path,\n",
        "      style_image_path,\n",
        "      content_blending_ratio,\n",
        "      gdrive_basedir,\n",
        "      gdrive_outdir\n",
        "    )\n",
        "    result_plot.imshow(result)\n",
        "\n",
        "preview_grid.subplots_adjust(hspace=0.20, wspace=0.05)\n",
        "\n",
        "print('\\nPreview Grid')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}